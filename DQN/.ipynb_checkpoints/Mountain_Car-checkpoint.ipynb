{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Q Network for Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.54664866,  0.        ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0').env\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for i in range(500):\n",
    "    env.render()\n",
    "    obs = env.step(2)\n",
    "    \n",
    "    if obs[2]:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(32,activation='relu',input_dim = 5))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,419\n",
      "Trainable params: 1,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create another model with same size and to learn quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_learn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_learn.add(Dense(32,activation='relu',input_dim = 5))\n",
    "model_learn.add(Dense(20,activation='relu'))\n",
    "model_learn.add(Dense(16,activation='relu'))\n",
    "model_learn.add(Dense(10,activation='relu'))\n",
    "model_learn.add(Dense(5,activation='relu'))\n",
    "model_learn.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 32)                192       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,419\n",
      "Trainable params: 1,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_learn.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start to play the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 2\n",
    "max_length_play = 9000\n",
    "discount_factor = 0.99\n",
    "learing_rate = 0.01\n",
    "epsilon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1075/1075 [==============================] - 0s 271us/step - loss: 12.4367\n",
      "Epoch 2/70\n",
      "1075/1075 [==============================] - 0s 249us/step - loss: 7.5277\n",
      "Epoch 3/70\n",
      "1075/1075 [==============================] - 0s 214us/step - loss: 7.0485\n",
      "Epoch 4/70\n",
      "1075/1075 [==============================] - 0s 328us/step - loss: 5.5408\n",
      "Epoch 5/70\n",
      "1075/1075 [==============================] - 0s 202us/step - loss: 4.5913\n",
      "Epoch 6/70\n",
      "1075/1075 [==============================] - 0s 320us/step - loss: 3.0990\n",
      "Epoch 7/70\n",
      "1075/1075 [==============================] - 0s 295us/step - loss: 3.4564\n",
      "Epoch 8/70\n",
      "1075/1075 [==============================] - 0s 200us/step - loss: 3.4800 0s - loss: 3.331\n",
      "Epoch 9/70\n",
      "1075/1075 [==============================] - 0s 186us/step - loss: 3.0159\n",
      "Epoch 10/70\n",
      "1075/1075 [==============================] - 0s 174us/step - loss: 3.4714\n",
      "Epoch 11/70\n",
      "1075/1075 [==============================] - 0s 268us/step - loss: 4.1089\n",
      "Epoch 12/70\n",
      "1075/1075 [==============================] - 0s 278us/step - loss: 3.2473\n",
      "Epoch 13/70\n",
      "1075/1075 [==============================] - 0s 224us/step - loss: 2.9967\n",
      "Epoch 14/70\n",
      "1075/1075 [==============================] - 0s 211us/step - loss: 3.1605\n",
      "Epoch 15/70\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 2.6841\n",
      "Epoch 16/70\n",
      "1075/1075 [==============================] - 0s 208us/step - loss: 2.3321\n",
      "Epoch 17/70\n",
      "1075/1075 [==============================] - 0s 207us/step - loss: 2.4346\n",
      "Epoch 18/70\n",
      "1075/1075 [==============================] - 0s 279us/step - loss: 2.2670\n",
      "Epoch 19/70\n",
      "1075/1075 [==============================] - 0s 260us/step - loss: 2.3297\n",
      "Epoch 20/70\n",
      "1075/1075 [==============================] - 0s 285us/step - loss: 3.1461\n",
      "Epoch 21/70\n",
      "1075/1075 [==============================] - 0s 236us/step - loss: 2.4922\n",
      "Epoch 22/70\n",
      "1075/1075 [==============================] - 0s 232us/step - loss: 2.4055\n",
      "Epoch 23/70\n",
      "1075/1075 [==============================] - 0s 219us/step - loss: 1.9324\n",
      "Epoch 24/70\n",
      "1075/1075 [==============================] - 0s 257us/step - loss: 1.8676\n",
      "Epoch 25/70\n",
      "1075/1075 [==============================] - 0s 215us/step - loss: 1.7613\n",
      "Epoch 26/70\n",
      "1075/1075 [==============================] - 0s 218us/step - loss: 1.7671\n",
      "Epoch 27/70\n",
      "1075/1075 [==============================] - 0s 264us/step - loss: 2.0264\n",
      "Epoch 28/70\n",
      "1075/1075 [==============================] - 0s 218us/step - loss: 2.1823\n",
      "Epoch 29/70\n",
      "1075/1075 [==============================] - 0s 215us/step - loss: 1.9869\n",
      "Epoch 30/70\n",
      "1075/1075 [==============================] - 0s 250us/step - loss: 2.1711\n",
      "Epoch 31/70\n",
      "1075/1075 [==============================] - 0s 250us/step - loss: 1.8705\n",
      "Epoch 32/70\n",
      "1075/1075 [==============================] - 0s 213us/step - loss: 1.7797\n",
      "Epoch 33/70\n",
      "1075/1075 [==============================] - 0s 173us/step - loss: 1.5932\n",
      "Epoch 34/70\n",
      "1075/1075 [==============================] - 0s 257us/step - loss: 1.5808\n",
      "Epoch 35/70\n",
      "1075/1075 [==============================] - 0s 263us/step - loss: 2.1723\n",
      "Epoch 36/70\n",
      "1075/1075 [==============================] - 0s 223us/step - loss: 2.0131\n",
      "Epoch 37/70\n",
      "1075/1075 [==============================] - 0s 282us/step - loss: 2.3705\n",
      "Epoch 38/70\n",
      "1075/1075 [==============================] - 0s 261us/step - loss: 1.4971\n",
      "Epoch 39/70\n",
      "1075/1075 [==============================] - 0s 218us/step - loss: 1.4576\n",
      "Epoch 40/70\n",
      "1075/1075 [==============================] - 0s 221us/step - loss: 1.3039\n",
      "Epoch 41/70\n",
      "1075/1075 [==============================] - 0s 216us/step - loss: 1.3117\n",
      "Epoch 42/70\n",
      "1075/1075 [==============================] - 0s 249us/step - loss: 1.6866\n",
      "Epoch 43/70\n",
      "1075/1075 [==============================] - 0s 202us/step - loss: 1.6970\n",
      "Epoch 44/70\n",
      "1075/1075 [==============================] - 0s 178us/step - loss: 1.5235\n",
      "Epoch 45/70\n",
      "1075/1075 [==============================] - 0s 172us/step - loss: 1.3022\n",
      "Epoch 46/70\n",
      "1075/1075 [==============================] - 0s 206us/step - loss: 1.8307\n",
      "Epoch 47/70\n",
      "1075/1075 [==============================] - 0s 219us/step - loss: 2.2166\n",
      "Epoch 48/70\n",
      "1075/1075 [==============================] - 0s 208us/step - loss: 1.9041\n",
      "Epoch 49/70\n",
      "1075/1075 [==============================] - 0s 212us/step - loss: 1.3764\n",
      "Epoch 50/70\n",
      "1075/1075 [==============================] - 0s 221us/step - loss: 1.3685\n",
      "Epoch 51/70\n",
      "1075/1075 [==============================] - 0s 213us/step - loss: 1.2388\n",
      "Epoch 52/70\n",
      "1075/1075 [==============================] - 0s 213us/step - loss: 1.2374\n",
      "Epoch 53/70\n",
      "1075/1075 [==============================] - 0s 222us/step - loss: 1.4915\n",
      "Epoch 54/70\n",
      "1075/1075 [==============================] - 0s 238us/step - loss: 1.1229\n",
      "Epoch 55/70\n",
      "1075/1075 [==============================] - 0s 241us/step - loss: 1.3471\n",
      "Epoch 56/70\n",
      "1075/1075 [==============================] - 0s 252us/step - loss: 1.7185\n",
      "Epoch 57/70\n",
      "1075/1075 [==============================] - 0s 196us/step - loss: 2.4962\n",
      "Epoch 58/70\n",
      "1075/1075 [==============================] - 0s 192us/step - loss: 1.6262\n",
      "Epoch 59/70\n",
      "1075/1075 [==============================] - 0s 188us/step - loss: 1.3813\n",
      "Epoch 60/70\n",
      "1075/1075 [==============================] - 0s 190us/step - loss: 1.1180 0s - loss: 0.6\n",
      "Epoch 61/70\n",
      "1075/1075 [==============================] - 0s 177us/step - loss: 1.3194\n",
      "Epoch 62/70\n",
      "1075/1075 [==============================] - 0s 191us/step - loss: 1.0754\n",
      "Epoch 63/70\n",
      "1075/1075 [==============================] - ETA: 0s - loss: 1.256 - 0s 196us/step - loss: 1.1807\n",
      "Epoch 64/70\n",
      "1075/1075 [==============================] - 0s 202us/step - loss: 1.2197\n",
      "Epoch 65/70\n",
      "1075/1075 [==============================] - 0s 194us/step - loss: 1.4781\n",
      "Epoch 66/70\n",
      "1075/1075 [==============================] - 0s 181us/step - loss: 1.6270\n",
      "Epoch 67/70\n",
      "1075/1075 [==============================] - 0s 177us/step - loss: 1.3208\n",
      "Epoch 68/70\n",
      "1075/1075 [==============================] - 0s 185us/step - loss: 1.4828\n",
      "Epoch 69/70\n",
      "1075/1075 [==============================] - 0s 209us/step - loss: 1.9803\n",
      "Epoch 70/70\n",
      "1075/1075 [==============================] - 0s 202us/step - loss: 1.6446\n",
      "Epoch 1/70\n",
      "293/293 [==============================] - 0s 211us/step - loss: 10.0227\n",
      "Epoch 2/70\n",
      "293/293 [==============================] - 0s 293us/step - loss: 12.2711\n",
      "Epoch 3/70\n",
      "293/293 [==============================] - ETA: 0s - loss: 11.31 - 0s 317us/step - loss: 10.2933\n",
      "Epoch 4/70\n",
      "293/293 [==============================] - 0s 218us/step - loss: 7.9484\n",
      "Epoch 5/70\n",
      "293/293 [==============================] - 0s 253us/step - loss: 6.0620\n",
      "Epoch 6/70\n",
      "293/293 [==============================] - 0s 209us/step - loss: 5.4746\n",
      "Epoch 7/70\n",
      "293/293 [==============================] - 0s 197us/step - loss: 7.0421\n",
      "Epoch 8/70\n",
      "293/293 [==============================] - 0s 242us/step - loss: 9.3858\n",
      "Epoch 9/70\n",
      "293/293 [==============================] - 0s 185us/step - loss: 5.0141\n",
      "Epoch 10/70\n",
      "293/293 [==============================] - 0s 196us/step - loss: 6.0931\n",
      "Epoch 11/70\n",
      "293/293 [==============================] - 0s 236us/step - loss: 5.7182\n",
      "Epoch 12/70\n",
      "293/293 [==============================] - 0s 378us/step - loss: 4.8022\n",
      "Epoch 13/70\n",
      "293/293 [==============================] - 0s 336us/step - loss: 4.0278\n",
      "Epoch 14/70\n",
      "293/293 [==============================] - 0s 220us/step - loss: 4.3864\n",
      "Epoch 15/70\n",
      "293/293 [==============================] - 0s 250us/step - loss: 4.0913\n",
      "Epoch 16/70\n",
      "293/293 [==============================] - 0s 310us/step - loss: 3.3123\n",
      "Epoch 17/70\n",
      "293/293 [==============================] - 0s 247us/step - loss: 3.2830\n",
      "Epoch 18/70\n",
      "293/293 [==============================] - 0s 320us/step - loss: 3.3462\n",
      "Epoch 19/70\n",
      "293/293 [==============================] - 0s 254us/step - loss: 3.4162\n",
      "Epoch 20/70\n",
      "293/293 [==============================] - 0s 215us/step - loss: 3.6862\n",
      "Epoch 21/70\n",
      "293/293 [==============================] - 0s 197us/step - loss: 3.6254\n",
      "Epoch 22/70\n",
      "293/293 [==============================] - 0s 190us/step - loss: 2.9891\n",
      "Epoch 23/70\n",
      "293/293 [==============================] - 0s 235us/step - loss: 3.0747\n",
      "Epoch 24/70\n",
      "293/293 [==============================] - 0s 259us/step - loss: 3.4157\n",
      "Epoch 25/70\n",
      "293/293 [==============================] - 0s 264us/step - loss: 3.1804\n",
      "Epoch 26/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 305us/step - loss: 2.9539\n",
      "Epoch 27/70\n",
      "293/293 [==============================] - 0s 272us/step - loss: 3.3501\n",
      "Epoch 28/70\n",
      "293/293 [==============================] - 0s 382us/step - loss: 3.4431\n",
      "Epoch 29/70\n",
      "293/293 [==============================] - 0s 189us/step - loss: 3.2753\n",
      "Epoch 30/70\n",
      "293/293 [==============================] - 0s 194us/step - loss: 2.9803\n",
      "Epoch 31/70\n",
      "293/293 [==============================] - 0s 183us/step - loss: 2.8574\n",
      "Epoch 32/70\n",
      "293/293 [==============================] - 0s 227us/step - loss: 2.7387\n",
      "Epoch 33/70\n",
      "293/293 [==============================] - 0s 180us/step - loss: 2.9285\n",
      "Epoch 34/70\n",
      "293/293 [==============================] - 0s 398us/step - loss: 3.2285\n",
      "Epoch 35/70\n",
      "293/293 [==============================] - 0s 364us/step - loss: 3.6429\n",
      "Epoch 36/70\n",
      "293/293 [==============================] - 0s 342us/step - loss: 3.2784\n",
      "Epoch 37/70\n",
      "293/293 [==============================] - 0s 273us/step - loss: 2.9640\n",
      "Epoch 38/70\n",
      "293/293 [==============================] - 0s 320us/step - loss: 3.1238\n",
      "Epoch 39/70\n",
      "293/293 [==============================] - 0s 342us/step - loss: 2.7655\n",
      "Epoch 40/70\n",
      "293/293 [==============================] - 0s 303us/step - loss: 3.2935\n",
      "Epoch 41/70\n",
      "293/293 [==============================] - 0s 224us/step - loss: 4.0212\n",
      "Epoch 42/70\n",
      "293/293 [==============================] - 0s 219us/step - loss: 3.9862\n",
      "Epoch 43/70\n",
      "293/293 [==============================] - 0s 235us/step - loss: 4.5550\n",
      "Epoch 44/70\n",
      "293/293 [==============================] - 0s 259us/step - loss: 4.1166\n",
      "Epoch 45/70\n",
      "293/293 [==============================] - 0s 300us/step - loss: 4.4888\n",
      "Epoch 46/70\n",
      "293/293 [==============================] - 0s 214us/step - loss: 5.1837\n",
      "Epoch 47/70\n",
      "293/293 [==============================] - 0s 287us/step - loss: 4.8798\n",
      "Epoch 48/70\n",
      "293/293 [==============================] - 0s 275us/step - loss: 4.8268\n",
      "Epoch 49/70\n",
      "293/293 [==============================] - 0s 183us/step - loss: 4.7926\n",
      "Epoch 50/70\n",
      "293/293 [==============================] - 0s 178us/step - loss: 4.2301\n",
      "Epoch 51/70\n",
      "293/293 [==============================] - 0s 215us/step - loss: 3.6286\n",
      "Epoch 52/70\n",
      "293/293 [==============================] - 0s 223us/step - loss: 3.1942\n",
      "Epoch 53/70\n",
      "293/293 [==============================] - 0s 225us/step - loss: 3.0108\n",
      "Epoch 54/70\n",
      "293/293 [==============================] - 0s 200us/step - loss: 2.6546\n",
      "Epoch 55/70\n",
      "293/293 [==============================] - 0s 283us/step - loss: 2.6097\n",
      "Epoch 56/70\n",
      "293/293 [==============================] - 0s 362us/step - loss: 2.9520\n",
      "Epoch 57/70\n",
      "293/293 [==============================] - 0s 270us/step - loss: 2.9154\n",
      "Epoch 58/70\n",
      "293/293 [==============================] - 0s 219us/step - loss: 2.7059\n",
      "Epoch 59/70\n",
      "293/293 [==============================] - 0s 348us/step - loss: 2.9071\n",
      "Epoch 60/70\n",
      "293/293 [==============================] - 0s 253us/step - loss: 2.9459\n",
      "Epoch 61/70\n",
      "293/293 [==============================] - 0s 232us/step - loss: 2.9096\n",
      "Epoch 62/70\n",
      "293/293 [==============================] - 0s 205us/step - loss: 2.7984\n",
      "Epoch 63/70\n",
      "293/293 [==============================] - ETA: 0s - loss: 6.414 - 0s 187us/step - loss: 2.7957\n",
      "Epoch 64/70\n",
      "293/293 [==============================] - 0s 204us/step - loss: 3.0058\n",
      "Epoch 65/70\n",
      "293/293 [==============================] - 0s 209us/step - loss: 2.9842\n",
      "Epoch 66/70\n",
      "293/293 [==============================] - 0s 265us/step - loss: 3.5062\n",
      "Epoch 67/70\n",
      "293/293 [==============================] - 0s 254us/step - loss: 5.0127\n",
      "Epoch 68/70\n",
      "293/293 [==============================] - 0s 200us/step - loss: 4.9011\n",
      "Epoch 69/70\n",
      "293/293 [==============================] - 0s 247us/step - loss: 3.9533\n",
      "Epoch 70/70\n",
      "293/293 [==============================] - 0s 225us/step - loss: 3.1563\n"
     ]
    }
   ],
   "source": [
    "for i in range(episode):\n",
    "    Experience = []\n",
    "    \n",
    "    epsilon = 1 / (np.sqrt(i+2800) + 1)\n",
    "    #epsilon = 1\n",
    "    \n",
    "    #implement SARSA\n",
    "    S = env.reset()\n",
    "    A = env.action_space.sample()\n",
    "    \n",
    "    for j in range(max_length_play):\n",
    "        \n",
    "        env.render()\n",
    "        observe = env.step(A)\n",
    "        \n",
    "        R = observe[2]\n",
    "        \n",
    "        S_new = observe[0]\n",
    "        \n",
    "        velocity = (S_new - S) / (0.1) \n",
    "        \n",
    "      \n",
    "        \n",
    "        #find Greedy action which give maximum value\n",
    "        Test = np.array([[S_new[0],S_new[1],velocity[0],velocity[1],0],\n",
    "                         [S_new[0],S_new[1],velocity[0],velocity[1],1],\n",
    "                         [S_new[0],S_new[1],velocity[0],velocity[1],2]])\n",
    "        \n",
    "        action_value = model.predict(Test)\n",
    "        \n",
    "        A_new = np.argmax(action_value)\n",
    "        \n",
    "        #Epsilon Greedy\n",
    "        val = np.random.uniform([0])\n",
    "        \n",
    "        if val > epsilon:\n",
    "            A_new = A_new\n",
    "        else :\n",
    "            A_new = np.random.choice([0,1,2])\n",
    "        \n",
    "        Target = np.max(action_value)\n",
    "        \n",
    "        if observe[2]:\n",
    "            Target = 1000\n",
    "            ep = 70\n",
    "            Experience.append([S[0],S[1],velocity[0],velocity[1],A,R+ (discount_factor *Target)])\n",
    "            break\n",
    "        else :\n",
    "            ep = 5\n",
    "        \n",
    "        Experience.append([S[0],S[1],velocity[0],velocity[1],A,R+ (discount_factor *Target)])\n",
    "        S = S_new\n",
    "        A = A_new\n",
    "    \n",
    "    Data = np.array(Experience)\n",
    "    \n",
    "    X_data = Data[:,[0,1,2,3,4]]\n",
    "    Y_data = Data[:,[5]]\n",
    "    \n",
    "    model.fit(X_data,Y_data, epochs=ep, batch_size= 64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weigts',by_name=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use another model to learn new Deep Q-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 2\n",
    "max_length_play = 9000\n",
    "discount_factor = 0.99\n",
    "learing_rate = 0.01\n",
    "epsilon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 2s 241us/step - loss: 1.1530\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 2s 208us/step - loss: 0.0381\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 2s 218us/step - loss: 0.0257\n",
      "Epoch 4/20\n",
      "9000/9000 [==============================] - 2s 182us/step - loss: 0.0205\n",
      "Epoch 5/20\n",
      "9000/9000 [==============================] - 2s 224us/step - loss: 0.0162\n",
      "Epoch 6/20\n",
      "9000/9000 [==============================] - 2s 202us/step - loss: 0.0152\n",
      "Epoch 7/20\n",
      "9000/9000 [==============================] - 2s 198us/step - loss: 0.0151\n",
      "Epoch 8/20\n",
      "9000/9000 [==============================] - 2s 245us/step - loss: 0.0160\n",
      "Epoch 9/20\n",
      "9000/9000 [==============================] - 2s 203us/step - loss: 0.0161\n",
      "Epoch 10/20\n",
      "9000/9000 [==============================] - 2s 177us/step - loss: 0.0233\n",
      "Epoch 11/20\n",
      "9000/9000 [==============================] - 2s 174us/step - loss: 0.0159\n",
      "Epoch 12/20\n",
      "9000/9000 [==============================] - 2s 201us/step - loss: 0.0211\n",
      "Epoch 13/20\n",
      "9000/9000 [==============================] - 2s 212us/step - loss: 0.1013\n",
      "Epoch 14/20\n",
      "9000/9000 [==============================] - 2s 256us/step - loss: 0.0992\n",
      "Epoch 15/20\n",
      "9000/9000 [==============================] - 2s 221us/step - loss: 0.5020\n",
      "Epoch 16/20\n",
      "9000/9000 [==============================] - 2s 254us/step - loss: 0.0152\n",
      "Epoch 17/20\n",
      "9000/9000 [==============================] - 2s 218us/step - loss: 0.0387\n",
      "Epoch 18/20\n",
      "9000/9000 [==============================] - 2s 233us/step - loss: 0.1411\n",
      "Epoch 19/20\n",
      "9000/9000 [==============================] - 2s 190us/step - loss: 0.5294\n",
      "Epoch 20/20\n",
      "9000/9000 [==============================] - 2s 199us/step - loss: 0.0152\n",
      "Epoch 1/20\n",
      "9000/9000 [==============================] - 2s 194us/step - loss: 1.2551\n",
      "Epoch 2/20\n",
      "9000/9000 [==============================] - 2s 204us/step - loss: 0.1402\n",
      "Epoch 3/20\n",
      "9000/9000 [==============================] - 2s 170us/step - loss: 0.1358\n",
      "Epoch 4/20\n",
      "9000/9000 [==============================] - 2s 169us/step - loss: 0.1554\n",
      "Epoch 5/20\n",
      "9000/9000 [==============================] - 2s 172us/step - loss: 0.2348\n",
      "Epoch 6/20\n",
      "9000/9000 [==============================] - 2s 222us/step - loss: 0.2820\n",
      "Epoch 7/20\n",
      "9000/9000 [==============================] - 2s 241us/step - loss: 0.3978\n",
      "Epoch 8/20\n",
      "9000/9000 [==============================] - 2s 259us/step - loss: 0.1331\n",
      "Epoch 9/20\n",
      "9000/9000 [==============================] - 2s 202us/step - loss: 0.2591\n",
      "Epoch 10/20\n",
      "9000/9000 [==============================] - 2s 200us/step - loss: 0.2216\n",
      "Epoch 11/20\n",
      "9000/9000 [==============================] - 2s 208us/step - loss: 1.1411\n",
      "Epoch 12/20\n",
      "9000/9000 [==============================] - 3s 280us/step - loss: 0.2729 0s - loss: \n",
      "Epoch 13/20\n",
      "9000/9000 [==============================] - 2s 200us/step - loss: 0.0943\n",
      "Epoch 14/20\n",
      "9000/9000 [==============================] - 2s 198us/step - loss: 0.0557\n",
      "Epoch 15/20\n",
      "9000/9000 [==============================] - 3s 342us/step - loss: 0.1359\n",
      "Epoch 16/20\n",
      "9000/9000 [==============================] - 2s 257us/step - loss: 0.4090\n",
      "Epoch 17/20\n",
      "9000/9000 [==============================] - 2s 211us/step - loss: 0.3321\n",
      "Epoch 18/20\n",
      "9000/9000 [==============================] - 2s 183us/step - loss: 0.1853\n",
      "Epoch 19/20\n",
      "9000/9000 [==============================] - 2s 223us/step - loss: 1.3577\n",
      "Epoch 20/20\n",
      "9000/9000 [==============================] - 2s 179us/step - loss: 0.0528\n"
     ]
    }
   ],
   "source": [
    "for i in range(episode):\n",
    "    Experience = []\n",
    "    \n",
    "    epsilon = 1 / (np.sqrt(i+280) + 1)\n",
    "   # epsilon = 1\n",
    "    \n",
    "    #implement SARSA\n",
    "    S = env.reset()\n",
    "    A = env.action_space.sample()\n",
    "    \n",
    "    for j in range(max_length_play):\n",
    "        \n",
    "        env.render()\n",
    "        observe = env.step(A)\n",
    "        \n",
    "        R = observe[2]\n",
    "        \n",
    "        S_new = observe[0]\n",
    "        \n",
    "        velocity = (S_new - S) / (0.1) \n",
    "        \n",
    "      \n",
    "        \n",
    "        #find Greedy action which give maximum value\n",
    "        Test = np.array([[S_new[0],S_new[1],velocity[0],velocity[1],0],\n",
    "                         [S_new[0],S_new[1],velocity[0],velocity[1],1],\n",
    "                         [S_new[0],S_new[1],velocity[0],velocity[1],2]])\n",
    "        \n",
    "        action_value = model_learn.predict(Test)\n",
    "        \n",
    "        A_new = np.argmax(action_value)\n",
    "        \n",
    "        #Epsilon Greedy\n",
    "        val = np.random.uniform([0])\n",
    "        \n",
    "        if val > epsilon:\n",
    "            A_new = A_new\n",
    "        else :\n",
    "            A_new = np.random.choice([0,1,2])\n",
    "        \n",
    "        Target = np.max(action_value)\n",
    "        \n",
    "        if observe[2]:\n",
    "            Target = 1000\n",
    "            ep = 70\n",
    "            Experience.append([S[0],S[1],velocity[0],velocity[1],A,R+ (discount_factor *Target)])\n",
    "            break\n",
    "        else :\n",
    "            ep = 20\n",
    "        \n",
    "        Experience.append([S[0],S[1],velocity[0],velocity[1],A,R+ (discount_factor *Target)])\n",
    "        S = S_new\n",
    "        A = A_new\n",
    "    \n",
    "    Data = np.array(Experience)\n",
    "    \n",
    "    X_data = Data[:,[0,1,2,3,4]]\n",
    "    Y_data = Data[:,[5]]\n",
    "    \n",
    "    model_learn.fit(X_data,Y_data, epochs=ep, batch_size= 64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_learn.save_weights('./learn_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model perform better than model learn beacause it done more exploration and reward is given only in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
