{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SARSAMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphics import *\n",
    "import random\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create 5x5 Grid world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = GraphWin(\"My Window\", 600,600)\n",
    "win.setBackground(color_rgb(255,255,255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x1,y1,x2,y2):\n",
    "    \"\"\"\n",
    "    create a line between pt(x1,y1) and pt(x2,y2) and return it\n",
    "    \"\"\"\n",
    "    ln = Line(Point(x1,y1),Point(x2,y2))\n",
    "    ln.setOutline(color_rgb(0,0,0))\n",
    "    ln.setWidth(2)\n",
    "    \n",
    "    return ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rectangle(Point(150.0, 250.0), Point(250.0, 350.0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#border lines\n",
    "border1 = line(50,50,550,50)\n",
    "border1.draw(win)\n",
    "\n",
    "border2 = line(550,50,550,550)\n",
    "border2.draw(win)\n",
    "\n",
    "border3 = line(50,550,550,550)\n",
    "border3.draw(win)\n",
    "\n",
    "border4 = line(50,50,50,550)\n",
    "border4.draw(win)\n",
    "\n",
    "#lines horizontal\n",
    "ln1 = line(50,150,550,150)\n",
    "ln1.draw(win)\n",
    "\n",
    "ln2 = line(50,250,550,250)\n",
    "ln2.draw(win)\n",
    "\n",
    "ln3 = line(50,350,550,350)\n",
    "ln3.draw(win)\n",
    "\n",
    "ln4 = line(50,450,550,450)\n",
    "ln4.draw(win)\n",
    "\n",
    "#lines vertical\n",
    "\n",
    "lnv1 = line(150,50,150,550)\n",
    "lnv1.draw(win)\n",
    "\n",
    "lnv2 = line(250,50,250,550)\n",
    "lnv2.draw(win)\n",
    "\n",
    "lnv3 = line(350,50,350,550)\n",
    "lnv3.draw(win)\n",
    "\n",
    "lnv4 = line(450,50,450,550)\n",
    "lnv4.draw(win)\n",
    "\n",
    "#create goal, obstacle and hole\n",
    "\n",
    "rect_goal = Rectangle(Point(450,50), Point(550,150))\n",
    "rect_goal.setFill(color_rgb(0,255,0))\n",
    "rect_goal.draw(win)\n",
    "\n",
    "rect_hole = Rectangle(Point(450,150), Point(550,250))\n",
    "rect_hole.setFill(color_rgb(255,0,0))\n",
    "rect_hole.draw(win)\n",
    "\n",
    "rect_obs1 = Rectangle(Point(150,350), Point(250,450))\n",
    "rect_obs1.setFill(color_rgb(0,0,0))\n",
    "rect_obs1.draw(win)\n",
    "\n",
    "rect_obs2 = Rectangle(Point(150,250), Point(250,350))\n",
    "rect_obs2.setFill(color_rgb(0,0,0))\n",
    "rect_obs2.draw(win)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create agent look like circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Circle(Point(100.0, 500.0), 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Circle(Point(100,500), 25)\n",
    "agent.setFill(color_rgb(0,0,255))\n",
    "agent.draw(win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up(agent):\n",
    "    val = agent.getCenter()\n",
    "    \n",
    "    if (val.getY()) == 100 or (val.getY() == 500 and val.getX() == 200) :\n",
    "        pass\n",
    "    else :\n",
    "        agent.move(0,-100)\n",
    "        \n",
    "    \n",
    "def down(agent):\n",
    "    val = agent.getCenter()\n",
    "    \n",
    "    if val.getY() == 500 or (val.getX() == 200 and val.getY() == 200):\n",
    "        pass\n",
    "    else :\n",
    "        agent.move(0,100)\n",
    "\n",
    "def right(agent):\n",
    "    val = agent.getCenter()\n",
    "    \n",
    "    if val.getX() == 500 or (val.getX() == 100 and (val.getY() == 300 or val.getY() == 400)):\n",
    "        pass\n",
    "    else :\n",
    "        agent.move(100,0)\n",
    "\n",
    "def left(agent):\n",
    "    val = agent.getCenter()\n",
    "    \n",
    "    if val.getX() == 100 or (val.getX() == 300 and (val.getY() == 300 or val.getY() == 400)):\n",
    "        pass\n",
    "    else:\n",
    "        agent.move(-100,0)\n",
    "        \n",
    "def action(agent,val):\n",
    "    if val == 0:\n",
    "        up(agent)\n",
    "    elif val == 1:\n",
    "        down(agent)\n",
    "    elif val == 2:\n",
    "        right(agent)\n",
    "    else :\n",
    "        left(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reward for agent in the each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = np.array([[-1,-1,-1,-1,-1],\n",
    "                   [-1,-20,-1,-1,-1],\n",
    "                   [-1,-20,-1,-1,-1],\n",
    "                   [-1,-1,-1,-1,-100],\n",
    "                   [-1,-1,-1,-1,100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewards(agent):\n",
    "    val = agent.getCenter()\n",
    "    i = int(val.getX() / 100) - 1\n",
    "    j = int((500 - val.getY()) / 100) \n",
    "    \n",
    "    \n",
    "    return reward[j][i]\n",
    "\n",
    "def observation(agent):\n",
    "    val = agent.getCenter()\n",
    "    i = int(val.getX() / 100) - 1\n",
    "    j = int((500 - val.getY()) / 100) \n",
    "    \n",
    "    return [i,j]\n",
    "\n",
    "def env_close():\n",
    "    win.close()\n",
    "\n",
    "def reset(agent):\n",
    "    agent.move(-400,400)\n",
    "\n",
    "def set_agent(agent,obs):\n",
    "    pos = agent.getCenter()\n",
    "    \n",
    "    pos = [pos.getX(), pos.getY()]\n",
    "    \n",
    "    refer_pos = [(obs[0]+1) * 100, (500 - (obs[1]*100))]\n",
    "    \n",
    "    \n",
    "    agent.move(refer_pos[0]-pos[0], refer_pos[1] - pos[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the value function and policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros([5,5,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q[4,4] = [100.,100.,100.,100.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 300\n",
    "max_episode_length = 50\n",
    "learning_rate = .01\n",
    "discount_factor = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(episode):  \n",
    "    epsilon = 1 / (sqrt(j)+1)\n",
    "    \n",
    "    S = observation(agent)\n",
    "    A = np.argmax(Q[S[0],S[1]])\n",
    "    \n",
    "    for i in range(max_episode_length):\n",
    "        action(agent,A)\n",
    "        \n",
    "        R = rewards(agent)\n",
    "        \n",
    "        S_new = observation(agent)\n",
    "        \n",
    "        p = random.uniform(0,1)\n",
    "        \n",
    "        if p > epsilon:\n",
    "            A_new = np.argmax(Q[S_new[0],S_new[1]])\n",
    "        else :\n",
    "            A_new = np.random.choice([0,1,2,3])\n",
    "        \n",
    "        #add probability to each action\n",
    "        if A_new == 0:\n",
    "            A_new = np.random.choice([0,1,2,3],p=[0.8,0,0.1,0.1])\n",
    "        elif A_new == 1:\n",
    "            A_new = np.random.choice([0,1,2,3],p=[0,0.8,0.1,0.1])\n",
    "        elif A_new == 2:\n",
    "            A_new = np.random.choice([0,1,2,3],p=[0.1,0.1,0.8,0])\n",
    "        elif A_new == 3:\n",
    "            A_new = np.random.choice([0,1,2,3],p=[0.1,0.1,0, 0.8])\n",
    "            \n",
    "       \n",
    "        #temporal difference learning\n",
    "    \n",
    "        Q[S[0],S[1],A] = Q[S[0],S[1],A] + (learning_rate * (R + (discount_factor * np.max(Q[S_new[0],S_new[1]])) - Q[S[0],S[1],A]))\n",
    " \n",
    "        S = S_new\n",
    "        A = A_new\n",
    "        \n",
    "        if (S[0] == 4) and (S[1] == 4):\n",
    "            reset(agent)\n",
    "            S = observation(agent)\n",
    "            A = np.argmax(Q[S[0],S[1]])\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 3.07461969e+01, -2.22834582e+00, -2.22366183e+00,\n",
       "         -2.21730565e+00],\n",
       "        [ 4.04343534e+01, -6.89566805e-01,  1.18791152e+01,\n",
       "          1.26555363e+01],\n",
       "        [ 5.01795922e+01,  1.30249883e+00,  1.98198841e+01,\n",
       "          1.87701356e+01],\n",
       "        [ 3.74899370e+00,  1.65442099e+01,  5.94337274e+01,\n",
       "          5.33127075e+00],\n",
       "        [ 3.47587155e-01,  3.22496566e+00,  1.87917044e+01,\n",
       "         -2.36575375e-01]],\n",
       "\n",
       "       [[-1.68895286e+00, -1.67354197e+00, -1.58640228e+00,\n",
       "         -1.65701294e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "        [ 1.96698821e+01,  3.23706875e+01,  6.91410946e+01,\n",
       "          2.69705300e+00],\n",
       "        [ 7.09831124e+00,  7.86432677e+00,  5.98753448e+01,\n",
       "          6.37576567e-02]],\n",
       "\n",
       "       [[-3.00877215e-01, -9.70335374e-01, -9.97451284e-01,\n",
       "         -1.10221974e+00],\n",
       "        [ 3.68739166e+00, -4.90674182e-01, -3.47345492e-01,\n",
       "         -4.21687632e-01],\n",
       "        [ 2.24681106e+01, -1.90194563e-01,  1.12017393e+00,\n",
       "          2.14766045e-01],\n",
       "        [ 7.87665619e+01,  1.84120223e+00,  4.27547367e+01,\n",
       "          3.06414610e+01],\n",
       "        [ 5.05427393e+01,  4.44749495e+01,  8.89470723e+01,\n",
       "          3.16860513e+00]],\n",
       "\n",
       "       [[-3.98905916e-01, -5.51238598e-01, -5.90728569e-01,\n",
       "         -5.59053013e-01],\n",
       "        [ 2.85995163e+00, -2.86784064e-01, -3.68677152e-01,\n",
       "         -3.11800421e-01],\n",
       "        [ 1.98130810e+01, -1.23239281e-01, -2.71695302e-01,\n",
       "          1.51788232e-01],\n",
       "        [ 8.12327862e+01,  5.95183332e-01, -2.96337250e+01,\n",
       "          1.54463644e+01],\n",
       "        [ 6.06790223e+01,  4.29263887e+01,  9.99968386e+01,\n",
       "          1.16268038e+01]],\n",
       "\n",
       "       [[-4.73064381e-01, -4.75948320e-01, -4.67282911e-01,\n",
       "         -4.67081538e-01],\n",
       "        [-3.42723899e-01, -3.35238392e-01, -3.32957117e-01,\n",
       "         -2.89330069e-01],\n",
       "        [-1.04708023e+01, -2.16484942e-01, -2.07038631e-01,\n",
       "          6.25446953e-01],\n",
       "        [ 3.70176369e+01, -2.18242125e-02, -6.35017351e+00,\n",
       "          4.13290829e+00],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in experience:\n",
    "    set_agent(agent,[exp[0],exp[1]])\n",
    "    action(agent,exp[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 2 2 \n",
      "2 0 0 2 2 \n",
      "0 0 0 0 2 \n",
      "0 0 0 0 2 \n",
      "3 3 3 0 0 \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        print(np.argmax(Q[i,j]), end= \" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After 300 episode with 50 step in each episode using SARSAMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| right| right| right| right|  GOAL  |\n",
    "|------|------|------|------|--------|\n",
    "| right| right|  up  |  up  |   up   |\n",
    "|------|------|------|------|--------|\n",
    "|  up  |      |  up  |  up  |  left  |\n",
    "|------|------|------|------|--------|\n",
    "|  up  |      |  up  |  up  |  left  |\n",
    "|------|------|------|------|--------|\n",
    "|  up  | right|  up  |  up  |  left  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After 1000 episode with 10 step in each episode using SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| right| right| right| right|  GOAL  |\n",
    "|------|------|------|------|--------|\n",
    "| right| right|  up  |  up  |   up   |\n",
    "|------|------|------|------|--------|\n",
    "|  up  |      |  up  |  up  |  left  |\n",
    "|------|------|------|------|--------|\n",
    "|  up  |      |  up  |  up  |  left  |\n",
    "|------|------|------|------|--------|\n",
    "|  up  | right|  up  | right|  right |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "win.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare both SARSA and SARSAMAX beacuse of exploratory behaviour in SARSAMAX make converge better policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
